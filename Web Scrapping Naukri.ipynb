{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3dbe985-a987-4e2c-842f-5d139e4bf3ec",
   "metadata": {},
   "source": [
    "### **Web Scrapping**\n",
    "#### • Web scraping is the process of extracting information from websites.\n",
    "#### • Two popular tools for this task are Selenium and BeautifulSoup.\n",
    "#### • Each has its strengths and is often used together to leverage their combined capabilities.\n",
    "\n",
    "### **BeautifulSoup**\n",
    "#### • BeautifulSoup is a library for parsing HTML and XML documents.\n",
    "#### • It helps to navigate the HTML structure, search for elements, and extract data.\n",
    "#### • It is particularly effective for handling and cleaning up the HTML after fetching it, making it easier to extract the desired information.\n",
    "\n",
    "### **Selenium**\n",
    "#### • Selenium is a powerful tool for automating web browsers.\n",
    "#### • It can simulate user interactions, such as clicking buttons, filling out forms, and scrolling through pages.\n",
    "#### • This makes it especially useful for scraping dynamic content that is loaded via JavaScript or requires user actions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e81e9c-bc27-4c2b-bf6e-96d0dd568622",
   "metadata": {},
   "source": [
    "## Import Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a325790b-bf27-4390-abb5-ace572079421",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# requests\n",
    "import requests\n",
    "\n",
    "# BeautifulSoup\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import time\n",
    "\n",
    "# selenium\n",
    "from selenium import webdriver \n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "# BeautifulSoup\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b555c8ec-5fe4-4168-90ac-5bd8045bcba6",
   "metadata": {},
   "source": [
    "### ***Libraries Used***\n",
    "\n",
    "#### ***Pandas***\n",
    "#### • This library is used for data manipulation and analysis.\n",
    "#### • It provides powerful data structures like DataFrames which are great for organizing and analyzing data scraped from websites.\n",
    "#### • For example, after scraping data you can use pandas to clean and save the data in various formats like CSV or Excel.\n",
    "\n",
    "#### ***Requests***\n",
    "#### • This library allows you to send HTTP requests using Python.\n",
    "#### • It's often used to fetch the HTML content of a webpage.\n",
    "#### • With requests, you can easily retrieve the page source which can then be parsed to extract the desired information.\n",
    "\n",
    "#### ***BeautifulSoup***\n",
    "#### • This library is used for parsing HTML and XML documents.\n",
    "#### • It makes it easy to navigate and search the HTML structure of a webpage.\n",
    "#### • After retrieving the HTML content using requests you can use BeautifulSoup to parse and extract specific elements of the webpage.\n",
    "\n",
    "#### ***Selenium***\n",
    "#### • This library is used for automating web browsers.\n",
    "#### • It allows you to interact with web pages, which is particularly useful for scraping dynamic content that is loaded via JavaScript.\n",
    "#### • Selenium can simulate user interactions such as clicking buttons, filling out forms and scrolling.\n",
    "\n",
    "#### ***Webdriver_manager***\n",
    "#### • This library is used to automatically manage browser drivers for Selenium.\n",
    "#### • Instead of manually downloading and setting up browser drivers, webdriver_manager handles the installation and setup for you.\n",
    "#### • This simplifies the process of ensuring you have the correct driver version for your browser."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c99229c-0f50-4d18-8d24-1b258d08414b",
   "metadata": {},
   "source": [
    "### ***Selinum Used Functions***\n",
    "##### *Webdriver, By, Chrome Service, Chrome Drive Manager,  Web Driver Wait, Expected Conditions, Action Chains*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7633dc-6b17-47ca-9a9f-273a35255c5b",
   "metadata": {},
   "source": [
    "#### Open Chrome Browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9dd04f0a-d2fe-450d-897e-e3ef984dfd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Up Selenium WebDriver\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddef152-408c-47dd-a804-bbc1486bdf95",
   "metadata": {},
   "source": [
    "#### Login Naukri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d72d45b6-37ea-4c0f-a65a-2a368f3c4c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Logged in successfully!\n"
     ]
    }
   ],
   "source": [
    "def login_naukri():\n",
    "    \n",
    "    # ==== Your Naukri Login Credentials ====\n",
    "    EmailId = 'sivaraman11velmurugan@gmail.com'\n",
    "    Pass_Word = '$iva5688'\n",
    "    \n",
    "    # Step 1: Open Naukri login page\n",
    "    driver.get(\"https://www.naukri.com/nlogin/login?URL=https://www.naukri.com/mnjuser/homepage\")\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # Step 2: Enter email and password\n",
    "    driver.find_element(By.ID, 'usernameField').send_keys(EmailId)\n",
    "    driver.find_element(By.ID, 'passwordField').send_keys(Pass_Word)\n",
    "    \n",
    "    # Step 3: Click login button\n",
    "    driver.find_element(By.XPATH, \"//button[@type='submit']\").click()\n",
    "    time.sleep(3)  # Wait to ensure login is complete\n",
    "    \n",
    "    print(\"✅ Logged in successfully!\")\n",
    "\n",
    "login_naukri()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac42c44c-384c-49de-943b-9463e73d49fe",
   "metadata": {},
   "source": [
    "#### Search Job related Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d5810f2-85e6-434a-bd7f-fba48e4adbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchBox_Activity(SEARCH_KEYWORDS, LOCATION):\n",
    "    \n",
    "    # Step 5: Find search box input field\n",
    "    search_box = driver.find_element(By.CLASS_NAME, 'nI-gNb-sb__main').click()\n",
    "    \n",
    "    ## Step 5: \n",
    "    ## Find the seacrch box\n",
    "    search_box_keywords = driver.find_element(By.XPATH, \"//input[@placeholder = 'Enter keyword / designation / companies']\")\n",
    "    \n",
    "    ## Clear and type your keyword\n",
    "    search_box_keywords.clear()\n",
    "    #search_box_keywords.send_keys(\"Data Analytics\")\n",
    "    search_box_keywords.send_keys(\", \".join(SEARCH_KEYWORDS))\n",
    "    \n",
    "    ## Step 6:\n",
    "    # Click on the Experience dropdown input box\n",
    "    exp_input = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.ID, \"experienceDD\"))\n",
    "    )\n",
    "    exp_input.click()\n",
    "    \n",
    "    ##  Click on \"1 year\" option\n",
    "    one_year_option = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, \"//li[@title='1 year']\"))\n",
    "    )\n",
    "    one_year_option.click()\n",
    "    \n",
    "    ## Step 6: \n",
    "    # Find search box location input field \n",
    "    search_box_location = driver.find_element(By.XPATH, \"//input[@placeholder= 'Enter location']\")\n",
    "    search_box_location.send_keys(\", \".join(LOCATION))\n",
    "    \n",
    "    # Click the search box\n",
    "    search_box = driver.find_element(By.CLASS_NAME, 'nI-gNb-sb__icon-wrapper').click()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d75b67-f711-4af6-b6a7-492d9700026e",
   "metadata": {},
   "source": [
    "#### Using Filters for ***Department*** specific job selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaa91eaa-0b36-49de-b62f-7291873eac26",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Using Filter Option from Naukri\n",
    "def filter_department(Dept_Keys):\n",
    "\n",
    "    ##  Department Field Open and Close\n",
    "    # Intially It's open only so Currently no need\n",
    "    '''\n",
    "    # Expand Department filter (optional, if collapsed)\n",
    "    dept_section = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, \"//span[text()='Department']\"))\n",
    "    )\n",
    "    dept_section.click()\n",
    "\n",
    "    time.sleep(1)\n",
    "    '''\n",
    "    # Select \"Data Science & Analytics\" checkbox\n",
    "    DS_DA_checkbox = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, f\"//div[@class='styles_chckBoxCont__t_dRs']//label[contains(., '{Dept_Keys}')]\"))\n",
    "    )\n",
    "    \n",
    "    DS_DA_checkbox.click()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fee7fbd-f074-4022-ba9d-b910a7ad2f96",
   "metadata": {},
   "source": [
    "#### Using Filters for ***Role*** specific job selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b328fb0e-8375-4a6d-9d4b-a593aa246fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the specific role \n",
    "def select_role(option_text):\n",
    "    '''\n",
    "    # Expand Role filter (optional, if collapsed)\n",
    "    role_section = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, \"//span[text()='Role category']\"))\n",
    "    )\n",
    "    #role_section.click()\n",
    "    '''\n",
    "    DS_DA_checkbox = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, f\"//div[@class='styles_chckBoxCont__t_dRs']//label[contains(., '{option_text}')]\"))\n",
    "    )\n",
    "    DS_DA_checkbox.click()\n",
    "    print(f\"✅ Selected option: {option_text}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b8fb59-11bc-4583-943c-912adbe03cef",
   "metadata": {},
   "source": [
    "#### Using Filters for ***Location*** specific job selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78b906b2-c418-4e1b-83f9-8d57dec05095",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filter Location\n",
    "\n",
    "def filter_location(location):\n",
    "    DS_DA_checkbox = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, f\"//div[@class='styles_chckBoxCont__t_dRs']//label[contains(., '{location}')]\"))\n",
    "    )\n",
    "    DS_DA_checkbox.click()\n",
    "    print(f\"✅ Selected option: {location}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5917f1b4-6f26-48e0-95d7-da25b6f9647f",
   "metadata": {},
   "source": [
    "#### Using Filters for ***Salary*** specific job selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cd2a7e5-a0c3-46a9-8989-7d2504f254b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filter Salary\n",
    "def filter_salary(salary):\n",
    "    \n",
    "    DS_DA_checkbox = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, f\"//div[@class='styles_chckBoxCont__t_dRs']//label[contains(., '{salary}')]\"))\n",
    "    )\n",
    "    \n",
    "    '''\n",
    "    DS_DA_checkbox = WebDriverWait(driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.XPATH, f\"//label[contains(@class, 'styles_chkLbl__n2x09') and contains(., '{salary}')]\"))\n",
    "    )\n",
    "    '''\n",
    "    DS_DA_checkbox.click()\n",
    "    print(f\"✅ Selected option: {salary}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "310e6748-0674-4f96-b13b-e7264b5a03bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.naukri.com/data-analyst-jobs-in-chennai?k=data%20analyst&l=chennai%2C%20coimbatore%2C%20bangalore&nignbevent_src=jobsearchDeskGNB&experience=1&functionAreaIdGid=3&cityTypeGid=97&cityTypeGid=183&cityTypeGid=184&ctcFilter=3to6\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3cc437df-1586-405b-b1f9-e31badc8256f",
   "metadata": {},
   "source": [
    "#### ***Scrapping the Company Details data which is get after applying search key words, filter for specific job list***\n",
    "#### Column Name - *Job Role, Company Name, Company URL, Experience, Location, Technical Skills, Rating, Review, Job Posted*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "832caeaf-880e-4e8e-a784-d8db1c0435e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scrapping():\n",
    "    # Step 1 : Get current page url\n",
    "    base_url = driver.current_url\n",
    "    print(base_url)\n",
    "    \n",
    "    # Step 2: Get page source and parse\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    \n",
    "    # Step 3: Find job cards using your div structure\n",
    "    job_cards = soup.select('div.cust-job-tuple')\n",
    "    \n",
    "    jobs = []\n",
    "    \n",
    "    for card in job_cards:\n",
    "        try:\n",
    "            # Company Name\n",
    "            company = card.select_one('a.comp-name').get_text(strip=True)\n",
    "        except:\n",
    "            company = None\n",
    "    \n",
    "    \n",
    "        try:\n",
    "            # Job Role (it's usually inside h2 but sometimes empty, fallback to job title)\n",
    "            job_title = card.select_one('a.title').get_text(strip=True)\n",
    "        except:\n",
    "            job_title = None\n",
    "    \n",
    "        try:\n",
    "            experience = card.select_one('span.expwdth').get_text(strip=True)\n",
    "        except:\n",
    "            experience = None\n",
    "            \n",
    "        try:\n",
    "            location = card.select_one('span.locWdth').get_text(strip=True)\n",
    "        except:\n",
    "            location = None\n",
    "            \n",
    "        try:\n",
    "            job_posted = card.select_one('span.job-post-day ').get_text(strip=True)\n",
    "        except:\n",
    "            location = None\n",
    "        try:\n",
    "            # Technical Skills (from tags)\n",
    "            skills = \", \".join([tag.get_text(strip=True) for tag in card.select('ul.tags-gt li')])\n",
    "        except:\n",
    "            skills = None\n",
    "    \n",
    "        try:\n",
    "            rating = card.select_one('a.rating').get_text(strip=True)\n",
    "        except:\n",
    "            rating = None\n",
    "            \n",
    "        try:\n",
    "            review = card.select_one('a.review').get_text(strip=True)\n",
    "        except:\n",
    "            review = None\n",
    "    \n",
    "        try:\n",
    "            company_url = card.select_one('a.comp-name')['href']\n",
    "        except:\n",
    "            company_url = None\n",
    "    \n",
    "        jobs.append({\n",
    "            'Job Role': job_title,\n",
    "            'Company Name': company,\n",
    "            'Company URL': company_url,\n",
    "            'Experience': experience,\n",
    "            'Location': location,\n",
    "            'Technical Skills': skills,\n",
    "            'Rating': rating,\n",
    "            'Review': review,\n",
    "            'Job Posted': job_posted\n",
    "        })\n",
    "\n",
    "\n",
    "    \n",
    "    return jobs\n",
    "    # Step 4: Convert to DataFrame\n",
    "    #df = pd.DataFrame(jobs)\n",
    "    #print(df,\"<---- df\")\n",
    "    \n",
    "    # Optional: Save to Excel\n",
    "    #df.to_excel(\"D:/Job Related/New folder/naukri_jobs_scraped.xlsx\", index=False)\n",
    "\n",
    "# driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0613810-8476-498b-aa7e-0cad82c250cd",
   "metadata": {},
   "source": [
    "#### Apply scrapping for multiple pages job list and convert excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a49ed1b5-d160-4153-9e39-4d9bb38a6854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multipage_excel():\n",
    "    try:\n",
    "        df = pd.DataFrame(columns=[\n",
    "            'Job Role', 'Company Name', 'Company URL', 'Experience', 'Location',\n",
    "            'Technical Skills', 'Rating', 'Review', 'Job Posted'\n",
    "        ])\n",
    "        for i in range(1, 5):  # start from 1 (pages start from 1)\n",
    "            page = str(i)\n",
    "            print(f\"Clicking page {page}\")\n",
    "            \n",
    "            pagination_div = driver.find_element(By.CLASS_NAME, 'styles_pages__v1rAK')\n",
    "            page_link = pagination_div.find_element(By.XPATH, f'.//a[text()=\"{page}\"]')\n",
    "            page_link.click()\n",
    "            jobs_list = scrapping()\n",
    "        \n",
    "            for row in jobs_list:\n",
    "                df = pd.concat([df, pd.DataFrame([row])], ignore_index=True)\n",
    "                \n",
    "            time.sleep(15)  # wait for page to load\n",
    "            \n",
    "        # Optional: Save to Excel\n",
    "        df.to_excel(\"D:/Job Related/New folder/naukri_jobs_scraped.xlsx\", index=False)\n",
    "        print(\"Shape of df\", df.shape)\n",
    "        print(\"First 10 rows\", df.head(10))\n",
    "        time.sleep(15)\n",
    "        print(f\"Result is {result}\")\n",
    "    \n",
    "\n",
    "    except ValueError:\n",
    "        # This block runs if there's a ValueError (like entering text instead of a number)\n",
    "        print(\"Please enter a valid number.\")\n",
    "    except ZeroDivisionError:\n",
    "        # This block runs if the user enters zero (division by zero)\n",
    "        print(\"Cannot divide by zero.\")\n",
    "    except Exception as e:\n",
    "        # This catches any other exceptions\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "    finally:\n",
    "        # This block always runs, whether there was an error or not\n",
    "        print(\"Execution completed.\")\n",
    "\n",
    "\n",
    "#multipage_excel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735b4cc5-3dac-437a-a144-3aa4f22f07c8",
   "metadata": {},
   "source": [
    "##### ***HERE HANDLING THE FUNCTIONS AND KEYWORDS.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97efaf70-ee7b-41f5-9950-80128012aeb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Selected option: Chennai\n",
      "✅ Selected option: 3-6 Lakhs\n",
      "https://www.naukri.com/data-analyst-jobs-in-chennai?k=data%20analyst&l=chennai&nignbevent_src=jobsearchDeskGNB&experience=1&functionAreaIdGid=3&cityTypeGid=183&ctcFilter=3to6\n",
      "Clicking page 1\n",
      "https://www.naukri.com/data-analyst-jobs-in-chennai?k=data%20analyst&l=chennai&nignbevent_src=jobsearchDeskGNB&experience=1&functionAreaIdGid=3&cityTypeGid=183&ctcFilter=3to6\n",
      "Clicking page 2\n",
      "https://www.naukri.com/data-analyst-jobs-in-chennai?k=data%20analyst&l=chennai&nignbevent_src=jobsearchDeskGNB&experience=1&functionAreaIdGid=3&cityTypeGid=183&ctcFilter=3to6\n",
      "Clicking page 3\n",
      "https://www.naukri.com/data-analyst-jobs-in-chennai-2?k=data+analyst&l=chennai&nignbevent_src=jobsearchDeskGNB&experience=1&functionAreaIdGid=3&cityTypeGid=183&ctcFilter=3to6\n",
      "Clicking page 4\n",
      "https://www.naukri.com/data-analyst-jobs-in-chennai-3?k=data+analyst&l=chennai&nignbevent_src=jobsearchDeskGNB&experience=1&functionAreaIdGid=3&cityTypeGid=183&ctcFilter=3to6\n",
      "Shape of df (80, 9)\n",
      "First 10 rows                                    Job Role                   Company Name  \\\n",
      "0                            Data Scientist      Kanini Software Solutions   \n",
      "1    Data Scientist / Senior Data Scientist           Applied Data Finance   \n",
      "2                        AI / ML Engineer I                     360DigiTMG   \n",
      "3  Fourth Partner Energy - AI/ML Engineer I                     360DigiTMG   \n",
      "4                     Senior Data Scientist                  Grid Dynamics   \n",
      "5                            Data Scientist           Applied Data Finance   \n",
      "6                   Python Backend Engineer                      Ascendeum   \n",
      "7                       Data Science and AI                Programming.Com   \n",
      "8                             Data Engineer                           Xoom   \n",
      "9                              Gis Engineer  Geoconsultants India Services   \n",
      "\n",
      "                                         Company URL Experience  \\\n",
      "0  https://www.naukri.com/kanini-solutions-jobs-c...    1-6 Yrs   \n",
      "1  https://www.naukri.com/applied-data-finance-jo...    1-3 Yrs   \n",
      "2  https://www.naukri.com/360digitmg-jobs-careers...    1-4 Yrs   \n",
      "3  https://www.naukri.com/360digitmg-jobs-careers...    1-4 Yrs   \n",
      "4  https://www.naukri.com/grid-dynamics-jobs-care...    1-4 Yrs   \n",
      "5  https://www.naukri.com/applied-data-finance-jo...    1-3 Yrs   \n",
      "6  https://www.naukri.com/ascendeum-jobs-careers-...    1-3 Yrs   \n",
      "7  https://www.naukri.com/programming-jobs-career...    1-4 Yrs   \n",
      "8  https://www.naukri.com/xoom-jobs-careers-12348...    0-2 Yrs   \n",
      "9  https://www.naukri.com/geoconsultants-india-se...    1-2 Yrs   \n",
      "\n",
      "                                            Location  \\\n",
      "0        Chennai, Coimbatore, Bengaluru, Noida, Pune   \n",
      "1                      Chennai, Bengaluru, Hyderabad   \n",
      "2                      Chennai, Bengaluru, Hyderabad   \n",
      "3                      Chennai, Bengaluru, Hyderabad   \n",
      "4                      Chennai, Bengaluru, Hyderabad   \n",
      "5                      Chennai, Bengaluru, Hyderabad   \n",
      "6  Chennai, Bengaluru, Kolkata, Mumbai, New Delhi...   \n",
      "7  Chennai, Bengaluru, Mumbai, Chandigarh, Pune, ...   \n",
      "8                                 Chennai, Bengaluru   \n",
      "9  Chennai, Bengaluru, Kolkata, Mumbai, New Delhi...   \n",
      "\n",
      "                                    Technical Skills Rating        Review  \\\n",
      "0  Unix, Linux, SAS, Coding, Application developm...    3.5  192  Reviews   \n",
      "1  data science, algorithms, business analytics, ...    4.5   43  Reviews   \n",
      "2  ML engineering, AI engineering, IoT platforms,...    4.0   87  Reviews   \n",
      "3  ML, MQTT, Azure, OPC-UA, Azure  Monitor, GCP, ...    4.0   87  Reviews   \n",
      "4  Data analysis, devops, Cloud, Medical insuranc...    3.2   43  Reviews   \n",
      "5  python, Power BI, mysql, Tableau, machine lear...    4.5   43  Reviews   \n",
      "6  Computer science, Backend, Data analysis, Fron...    4.1   21  Reviews   \n",
      "7  Data analysis, data science, Artificial Intell...    3.8  101  Reviews   \n",
      "8  Performance tuning, Coding, Manager Technology...   None          None   \n",
      "9  GIS, Telecom, Consulting, Open source, Data mi...   None          None   \n",
      "\n",
      "     Job Posted  \n",
      "0  30+ Days Ago  \n",
      "1   11 Days Ago  \n",
      "2   12 Days Ago  \n",
      "3   12 Days Ago  \n",
      "4  30+ Days Ago  \n",
      "5  30+ Days Ago  \n",
      "6  30+ Days Ago  \n",
      "7  30+ Days Ago  \n",
      "8  30+ Days Ago  \n",
      "9  30+ Days Ago  \n",
      "An unexpected error occurred: name 'result' is not defined\n",
      "Execution completed.\n"
     ]
    }
   ],
   "source": [
    "SEARCH_KEYWORDS = [\"Data Analyst\"]\n",
    "LOCATION = [\"Chennai\"]\n",
    "# \"Coimbatore\",\"Bangalore\"\n",
    "\n",
    "searchBox_Activity(SEARCH_KEYWORDS, LOCATION)\n",
    "time.sleep(5)\n",
    "\n",
    "Dept_Keys = 'Data Science & Analytics'\n",
    "filter_department(Dept_Keys)\n",
    "time.sleep(5)\n",
    "\n",
    "#####   __Role Selection__   #####\n",
    "# 1) Select \"Data Science & Machine Learning\"\n",
    "# select_role(\"Data Science & Machine Learning\")\n",
    "# time.sleep(1)\n",
    "\n",
    "# 2) Select \"Data Science & Analytics - Other\"\n",
    "# select_role(\"Data Science & Analytics - Other\")\n",
    "# time.sleep(1)\n",
    "\n",
    "# 3) Select \"Business Intelligence & Analytics\"\n",
    "# select_role(\"Business Intelligence & Analytics\")\n",
    "\n",
    "#####   __Locations__   #####\n",
    "filter_location(\"Chennai\")\n",
    "time.sleep(3)\n",
    "# filter_location(\"Coimbatore\")\n",
    "\n",
    "#filter_location(\"Bengaluru\")\n",
    "# time.sleep(3)\n",
    "\n",
    "#####   __Salary__   #####\n",
    "salary = \"3-6 Lakhs\"\n",
    "filter_salary(salary)\n",
    "time.sleep(3)\n",
    "#filter_salary(\"6-10 Lakhs\")\n",
    "\n",
    "#####   __Scarapping Functions__   #####\n",
    "scrapping()\n",
    "time.sleep(15)\n",
    "\n",
    "#####   __MultipageDF Excel Convertion__   #####\n",
    "multipage_excel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693ccfe7-eb40-4b05-9dd3-3a96066e4a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####   __MultipageDF Excel Convertion__   #####\n",
    "multipage_excel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f202a0ba-2f57-44a5-b13d-b363b334f5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Find search box, enter keywords, and press Enter\n",
    "#SEARCH_KEYWORDS = [\"Data Analytics\", \"Data Analyst\", \"Data analysis Analyst\", \"Data analytics Analyst\",\"Data Manipulation\",\"Data visualization\", \"Data Cleansing\", ]\n",
    "#SEARCH_KEYWORDS = [\"Data Analytics\", \"Data Analyst\", \"Data visualization\", \"Data Manipulation\", \"Data Cleansing\"]\n",
    "#SEARCH_KEYWORDS = [\"Data analysis Analyst\", \"Data analytics Analyst\", \"Pandas\", \"Data Processing\", \"Data Manipulation\", \"data extraction\"]\n",
    "#SEARCH_KEYWORDS = [\"python data analyst\", \"data analyst with python\", ]\n",
    "#[\"Python Data Analytics\"]\n",
    "#data analyst, data analysis, data analytics, data visualization, data manipulation, data cleaning, data transformation,  raw data into actionable business intelligence \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
